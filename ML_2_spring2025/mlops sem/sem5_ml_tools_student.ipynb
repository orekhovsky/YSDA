{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# **Seminar 5 - Инструменты разработки**\n",
    "*Naumov Anton (Any0019)*\n",
    "\n",
    "*To contact me in telegram: @any0019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HuggingFace ( https://huggingface.co ) - один из ваших лучших друзей как ML-щиков\n",
    "\n",
    "Это платформа для машинного обучения.\n",
    "\n",
    "На платформе можно найти, а также добавлять и хостить модели, датасеты, api-ки\n",
    "\n",
    "Также платформа имеет серьёзную и очень сильную python-библиотеку (вернее целое семейство библиотек) для ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 python-библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У HuggingFace есть целый набор библиотек для ML\n",
    "\n",
    "Для работы с моделями ( https://huggingface.co/docs/hub/models-libraries ), из самых важных:\n",
    "- transformers - для работы с NLP\n",
    "- diffusers - для работы с диффузионками\n",
    "- PEFT - Parameter-Efficient Fine-Tuning (Lora)\n",
    "\n",
    "Для работы с данными ( https://huggingface.co/docs/hub/datasets-libraries ), из самых важных:\n",
    "- datasets - датасеты :)\n",
    "\n",
    "В целом это даже близко не полный список ( https://github.com/huggingface ):\n",
    "- evaluate ( https://github.com/huggingface/evaluate ) - разные метрики / бенчмарки\n",
    "- accelerate ( https://github.com/huggingface/accelerate ) - multi-gpu обучения\n",
    "- optimum ( https://github.com/huggingface/optimum ) - оптимизация инференса\n",
    "- ...\n",
    "\n",
    "sklearn в мире DL :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch transformers datasets evaluate scikit-learn accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Transformers - pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Концепция pipeline-ов такова, что объединяются 3 вещи в одну конструкцию:\n",
    "1. Пре-процессинг (токенизация, ...)\n",
    "2. Модель\n",
    "3. Пост-процессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    task='sentiment-analysis',\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier(\"This model is nice!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier(\n",
    "    [\n",
    "        \"What an awful thing...\",\n",
    "        \"It's great in what it was designed for, but kinda awful that everything is done for me\",\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?classifier.postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlm_model = pipeline('fill-mask', model=\"bert-base-uncased\")\n",
    "mlm_model = pipeline(task='fill-mask', model=\"bert-base-cased\")\n",
    "MASK = mlm_model.tokenizer.mask_token\n",
    "\n",
    "for hypo in mlm_model(f\"Donald {MASK} is the president of the united states.\"):\n",
    "  print(f\"P={hypo['score']:.5f}\", hypo['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del classifier, mlm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество моделей под самые разные задачи - быстро найти любые модели: https://huggingface.co/models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "text = \"\"\"Almost two-thirds of the 1.5 million people who viewed this liveblog had Googled to discover\n",
    " the latest on the Rosetta mission. They were treated to this detailed account by the Guardian’s science editor,\n",
    " Ian Sample, and astronomy writer Stuart Clark of the moment scientists landed a robotic spacecraft on a comet \n",
    " for the first time in history, and the delirious reaction it provoked at their headquarters in Germany.\n",
    "  “We are there. We are sitting on the surface. Philae is talking to us,” said one scientist.\n",
    "\"\"\"\n",
    "\n",
    "# Задача: Создайте pipeline для Named Entity Recognition (NER) задачи, ищите модельки на хабе\n",
    "#  - либо по тексту ner в названии\n",
    "#  - либо по задаче Token Classification\n",
    "ner_model = ...\n",
    "\n",
    "named_entities = ner_model(text)\n",
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_entity = {item['word']: item['entity'] for item in named_entities}\n",
    "assert 'org' in word_to_entity.get('Guardian').lower() and 'per' in word_to_entity.get('Stuart').lower()\n",
    "print(\"All tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transformers - model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"Luke, I am your father.\",\n",
    "    \"Life is what happens when you're busy making other plans.\",\n",
    "]\n",
    "\n",
    "# токенизация батча текстов. \"pt\" - [p]y[t]orch tensors\n",
    "tokens_info = tokenizer(lines, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "for key in tokens_info:\n",
    "    print(key, tokens_info[key].shape, tokens_info[key], sep=\"\\n\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Detokenized:\")\n",
    "for i in range(2):\n",
    "    print(tokenizer.decode(tokens_info['input_ids'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_analyse = \"some random text for deeper analysis + weird word Rutherfordium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tokenizer(text_for_analyse).items():\n",
    "    print(key, value, sep=\"\\n\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(text_for_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer.encode(text_for_analyse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(tokenizer.encode(text_for_analyse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(text_for_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    tokenizer.all_special_ids,\n",
    "    tokenizer.all_special_tokens,\n",
    "    tokenizer.all_special_tokens_extended,\n",
    "    tokenizer.added_tokens_encoder,\n",
    "    tokenizer.added_tokens_decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"Luke, I am your father.\",\n",
    "    \"Life is what happens when you're busy making other plans.\",\n",
    "]\n",
    "\n",
    "tokens_info = tokenizer(lines, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# прямой проход через модель\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens_info)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.layer[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/datasets/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"fancyzhx/yelp_polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train\"][0:5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenize_function(ds[\"train\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = ds.map(tokenize_function, batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1024))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "small_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"label\", \"attention_mask\"])\n",
    "dataloader = DataLoader(small_train_dataset, batch_size=4)\n",
    "res = next(iter(dataloader))\n",
    "\n",
    "for key, value in res.items():\n",
    "    print(key, value.shape, value, sep=\"\\n\", end=\"\\n-------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умеет много чего\n",
    "```python\n",
    "ds.rename_column(\"text\", \"unsplit_text\")  # переименовывать колонки\n",
    "ds.cast_column(\"image\", Image(mode=\"RGB\"))  # приводить отдельные колонки к нужному виду\n",
    "dataset.with_transform(transforms)  # аугументации на бегу\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/evaluate/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.compute(predictions=[1, 2, 3, 4], references=[1, 1, 1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.compute(predictions=[1, 2, 3, 4], references=[4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.compute(predictions=[1, 2, 3, 4], references=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Transformers - Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "?TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./my_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    # lr_scheduler_kwargs={},\n",
    "    # warmup_ratio=0.03125,\n",
    "    # warmup_steps=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    log_level=\"error\",\n",
    "    # logging_dir=\"output_dir/runs/CURRENT_DATETIME_HOSTNAME\"  # логи для tensorboard (default)\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    # save_steps=1,\n",
    "    save_total_limit=2,\n",
    "    save_safetensors=True,  # safetensors вместо torch.save / torch.load\n",
    "    save_only_model=False,  # сохраняем optimizer, shceduler, rng, ...\n",
    "    use_cpu=False,\n",
    "    seed=42,\n",
    "    # bf16=True,  # использовать bf16 вместо fp32\n",
    "    eval_strategy=\"epoch\",\n",
    "    # eval_steps=32,\n",
    "    disable_tqdm=False,\n",
    "    load_best_model_at_end=False,\n",
    "    label_smoothing_factor=0.,\n",
    "    optim=\"adamw_torch\",\n",
    "    # optim_args=...,\n",
    "    # resume_from_checkpoint=...,\n",
    "    # auto_find_batch_size=...,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"This was not a good movie!\",\n",
    "    \"What an awesome place!\",\n",
    "    \"ewww\",\n",
    "]\n",
    "\n",
    "tokens_info = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "with torch.no_grad():\n",
    "    out = model(**tokens_info)\n",
    "    probs = torch.nn.functional.softmax(out.logits, dim=-1)\n",
    "    for text, prob in zip(texts, probs.tolist()):\n",
    "        print(\n",
    "            f\"Text: `{text}`\\nPrediction (prob): \"\n",
    "            f\"positive={round(prob[0], 3)} ; \"\n",
    "            f\"negative={round(prob[1], 3)}\",\n",
    "            end=\"\\n\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. StreamLit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StreamLit - простая библиотека для построения интерактивных веб-приложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "streamlit hello  # демо с кодом от самого streamlit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приложения через streamlit строятся построчно, а не от макета\n",
    "\n",
    "Основные принципы:\n",
    "1. Используй скрипты на Python. Построчно создавайте и расширяйте приложения Streamlit.\n",
    "2. Рассматривай виджеты как переменные. Виджеты - это элементы ввода, которые позволяют пользователям взаимодействовать с приложениями Streamlit. Они представлены в виде основных текстовых полей ввода, флажков, ползунков и т.д.\n",
    "3. Повторно используй данные и вычисления. Исторически данные и вычисления кэшировались с помощью @st.cache декоратора. Это экономит вычислительное время при внесении изменений в приложение. Это может происходить сотни раз, если ты активно редактируешь приложение! В версии 0.89.0 Streamlit запустил два новых примитива (st.experimental_memo и st.experimental_singleton), что позволило значительно повысить скорость работы по сравнению с @st.cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн приложения\n",
    "1. Создаётся и заполняется файл `app.py` (default, можете свой)\n",
    "2. `streamlit run app.py`\n",
    "3. Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"This is a title\")\n",
    "st.header(\"This is a header\")\n",
    "st.subheader(\"This is a subheader\")\n",
    "st.text(\"This is a text\")\n",
    "st.markdown(\"# This is a markdown header 1\")\n",
    "st.markdown(\"## This is a markdown header 2\")\n",
    "st.markdown(\"### This is a markdown header 3\")\n",
    "st.markdown(\"This is a markdown: *bold* **italic** `inline code` ~strikethrough~\")\n",
    "st.markdown(\"\"\"This is a code block with syntax highlighting\n",
    "```python\n",
    "print(\"Hello world!\")\n",
    "```\n",
    "\"\"\")\n",
    "st.html(\n",
    "    \"image from url example with html: \"\n",
    "    \"<img src='https://www.wallpaperflare.com/static/450/825/286/kitten-cute-animals-grass-5k-wallpaper.jpg' width=400px>\",\n",
    ")\n",
    "\n",
    "\n",
    "st.write(\"Text with write\")\n",
    "st.write(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Логирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.success(\"Success\")\n",
    "st.info(\"Information\")\n",
    "st.warning(\"Warning\")\n",
    "st.error(\"Error\")\n",
    "exp = ZeroDivisionError(\"Trying to divide by Zero\")\n",
    "st.exception(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Объекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "request.urlretrieve(\n",
    "    \"http://craphound.com/images/1006884_2adf8fc7.jpg\",\n",
    "    \"image_example.jpg\",\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open(\"image_example.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# картинка (без html - из переменной)\n",
    "st.image(img, width=200)\n",
    "\n",
    "# чекбокс\n",
    "if st.checkbox(\"Show/Hide\"):\n",
    "    st.text(\"Showing the widget\")\n",
    "else:\n",
    "    st.warning(\"Not showing what is inside\")\n",
    "\n",
    "# выбор опции кружочками\n",
    "status = st.radio(\"Select Gender: \", ('Male', 'Female'))\n",
    "if (status == 'Male'):\n",
    "    st.success(\"Male\")\n",
    "else:\n",
    "    st.success(\"Female\")\n",
    "\n",
    "# выбор опции выпадающим меню\n",
    "hobby = st.selectbox(\n",
    "    \"Hobbies: \",\n",
    "    ['Dancing', 'Reading', 'Sports'],\n",
    ")\n",
    "st.write(\"Your hobby is: \", hobby)\n",
    "\n",
    "# выбор нескольких опций\n",
    "hobbies = st.multiselect(\n",
    "    \"Hobbies: \",\n",
    "    ['Dancing', 'Reading', 'Sports'],\n",
    ")\n",
    "st.write(\"You selected\", len(hobbies), 'hobbies')\n",
    "\n",
    "# кнопка без функционала\n",
    "st.button(\"Click me for no reason\")\n",
    "\n",
    "# кнопка, показывающая текст, когда нажата\n",
    "if(st.button(\"Click me\")):\n",
    "    st.text(\"You did it, you clicked me!!!\")\n",
    "\n",
    "# текстовый input: label - название, value - что написано по дефолту\n",
    "name = st.text_input(label=\"Enter Your name\", value=\"Type Here ...\")\n",
    "if(st.button('Submit')):\n",
    "    result = name.title()\n",
    "    st.success(result)\n",
    "\n",
    "# слайдер\n",
    "level = st.slider(\"Select the level\", 1, 5)\n",
    "st.text('Selected: {}'.format(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Сложные действия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Переменная общая на rerun - способ шейрить информацию между изменениями\n",
    "st.session_state  # kinda Dict[str, Any]\n",
    "\n",
    "# Инициализация\n",
    "if 'key' not in st.session_state:\n",
    "    st.session_state['key'] = 'value'\n",
    "\n",
    "# Можно также обращаться по атрибутам, а не ключам\n",
    "if 'key' not in st.session_state:\n",
    "    st.session_state.key = 'value'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем переменные\n",
    "st.session_state.key1 = 'value1'     # Attribute API\n",
    "st.session_state['key2'] = 'value2'  # Dictionary like API\n",
    "\n",
    "# посмотреть что в st.session_state\n",
    "st.write(st.session_state)\n",
    "\n",
    "# magic\n",
    "st.session_state\n",
    "\n",
    "# ошибка если неправильный ключ\n",
    "st.write(st.session_state['missing_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key - позволяет указать в какое поле session_state записать объект\n",
    "st.text_input(\"Please input something\", key=\"my input\")\n",
    "st.session_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Кэширование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кэширования есть 2 декоратора\n",
    "\n",
    "```python\n",
    "@st.cache_data      # для данных - сериализация выходов с ключами входов\n",
    "@st.cache_resource  # для моделей / ресурсов - несериализуемые объекты, которые не хочется загружать несколько раз\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "@st.cache_data  # кэширование\n",
    "def load_data(url):\n",
    "    df = pd.read_csv(url)  # скачивание датасета\n",
    "    return df\n",
    "\n",
    "df = load_data(\"https://github.com/plotly/datasets/raw/master/uber-rides-data1.csv\")\n",
    "st.dataframe(df)\n",
    "\n",
    "st.button(\"Rerun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "\n",
    "@st.cache_resource  # кэширование\n",
    "def load_model():\n",
    "    return pipeline(\"sentiment-analysis\")  # скачивание модели\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "query = st.text_input(\"Your query\", value=\"I love Streamlit! 🎈\")\n",
    "if query:\n",
    "    result = model(query)[0]  # классифицируем\n",
    "    st.write(query)\n",
    "    st.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HF + StreamLit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно поднять тестовую streamlit api прямо на hugging face\n",
    "\n",
    "1. https://huggingface.co/\n",
    "2. New space - Streamlit\n",
    "3. Делаем `app.py` и `requirements.txt`\n",
    "4. Собирается докер образ - появляется app (публично доступен)\n",
    "5. \\* немного хулиганства - можно достать даже iframe из hf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "any0019_personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
