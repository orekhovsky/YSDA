{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f6e808-2603-4fad-bcba-b5ad352e8d8c",
   "metadata": {},
   "source": [
    "# **Лабораторная работа**\n",
    "*Naumov Anton (Any0019)*\n",
    "\n",
    "*To contact me in telegram: @any0019*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680bac2-965d-4af1-bd5d-e2ff381d1edd",
   "metadata": {},
   "source": [
    "В данном задании вашей задачей будет построить и обучить модель CycleGAN для задачи Img2Img.\n",
    "\n",
    "---\n",
    "\n",
    "Про задачу __Img2Img__:\n",
    "\n",
    "- У вас есть 2 множества изображений ($A$ и $B$)\n",
    "- Ваша задача - научиться превращать изображения из множества $A$ в изображения из множества $B$ и наоборот\n",
    "- Бывают paired и unpaired множества\n",
    "- В случае __paired__ множеств - для каждого изображения из $A$ существует конкретное изображение из $B$, в которое оно должно перейти (и наоборот). Примером такой пары множеств может быть (а) спутниковая фотграфия местности vs схематическая карта местности , (б) фотография фасада здания vs схема фасада здания , ...\n",
    "- В случае __unpaired__ множеств - между множествами нет конкретных пар. Примером такой пары множеств может быть (а) фотографии с лошадьми vs фотографии с зебрами , (б) фотографии vs рисунки конкретного художника , ...\n",
    "\n",
    "---\n",
    "\n",
    "Про модель __CycleGAN__:\n",
    "\n",
    "- Модель придумана для задачи Img2Img (в первую очередь unpaired версии) и основана на концепции GAN-ов\n",
    "- В модели есть 2 генератора: $G_{A -> B}$ (задача которого - принимая на вход изображение из множества $A$ переводить его в изображение из множества $B$) и $G_{B -> A}$ (аналогично в другую сторону)\n",
    "- Надо отметить что на вход генераторы не получают никакую дополнительную случайность, что делает обучение таких моделей проще\n",
    "- В модели так же есть 2 дискриминатора: $D_{A}$ (задача которого - отличать реальные изображения из $A$ от сгенерированных с помощью $G_{B -> A}$ изображений) и $D_{B}$ (аналогично для $B$)\n",
    "- Функцией ошибки будет, как и для GAN-ов, minmax игра между генераторами и дискриминаторами, но к ошибке генераторов добавится ещё и, так называемый, `cycle consistency loss`, который проверяет, что после двойного перехода изображения не меняются $G_{B -> A} \\big( G_{A -> B} ( a ) \\big) = a ; \\forall a \\in A$ и $G_{A -> B} \\big( G_{B -> A} ( b ) \\big) = b ; \\forall b \\in B$\n",
    "- Так же можно добавлять или нет штраф за то, чтобы $G_{B -> A}$ не меняла изображения из $A$ и наоборот $G_{A -> B}$ не меняла изображения из $B$\n",
    "- Оригинальная статья: https://arxiv.org/pdf/1703.10593.pdf\n",
    "\n",
    "---\n",
    "\n",
    "Ваша задача - ноутбук разбит на несколько частей, каждая со своими баллами\n",
    "\n",
    "1. __Подготовка данных__ _(2 балла)_ --> требуется выбрать датасет для обучения (дано несколько на выбор) и составить пайплайн подготовки данных\n",
    "2. __Составление модели__ _(6 баллов)_ --> требуется собрать нейросеть _(3 балла)_ и создать функции ошибки _(3 балла)_\n",
    "3. __Подготовка обучения__ _(2 балла)_ --> требуется написать шаги обучения и валидации, визуализацию, а так же полный цикл обучения\n",
    "4. __Обучение__ _(2 балла)_ --> требуется обучить модель\n",
    "5. __Сбор своего датасета и обучение модели на нём__ _(3 балла)_ --> требуется собрать свой датасет и обучить на нём модель\n",
    "\n",
    "***За наиболее интересные и качественные решения в пункте 5 так же предусмотрены дополнительные баллы***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66589979-be69-4891-8925-afd0b1401202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms as tr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для тёмной темы jupyter - уберите если не нужно\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import cv2\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b960d0-a472-4b92-a28d-25c5f056954e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Подготовка данных (___2 балла___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f52ff0-7751-461e-8344-3d50575bf271",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.1 Выбор и скачивание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870cac5-544d-4bc9-856a-704436f34be1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = \"/home/jupyter/datasphere/project/datasets/img2img\"\n",
    "num_images_per_split = 5\n",
    "\n",
    "os.environ[\"dataset_folder\"] = dataset_folder\n",
    "!mkdir -p ${dataset_folder}\n",
    "\n",
    "# В этом цикле каждый из предложенных датасетов\n",
    "#  - скачивается\n",
    "#  - распаковывается\n",
    "#  - отрисовывается + meta\n",
    "#  - удаляется\n",
    "\n",
    "# Предлагается посмотреть на все предложенные варианты датасетов и затем оставить один,\n",
    "#  с которым захочется работать больше всего - закомментируйте (или удалите) все, кроме\n",
    "#  выбранного, а так же закомментируйте строчки с удалением скачанного датасета\n",
    "for dataset_name in [\n",
    "    # Unpaired\n",
    "    \"apple2orange\",\n",
    "    \"summer2winter_yosemite\",\n",
    "    \"horse2zebra\",\n",
    "    \"monet2photo\",\n",
    "    \"cezanne2photo\",\n",
    "    \"ukiyoe2photo\",\n",
    "    \"vangogh2photo\",\n",
    "    # Paired\n",
    "    \"maps\",\n",
    "    \"facades\",\n",
    "]:\n",
    "    print(f\"Dataset '{dataset_name}'\")\n",
    "    url = f\"http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/{dataset_name}.zip\"\n",
    "    download_path = os.path.join(dataset_folder, f\"{dataset_name}.zip\")\n",
    "    target_folder = os.path.join(dataset_folder, dataset_name)\n",
    "    \n",
    "    # Чтобы bash вызовы знали соответствующие переменные\n",
    "    os.environ[\"url\"] = url\n",
    "    os.environ[\"download_path\"] = download_path\n",
    "    os.environ[\"target_folder\"] = target_folder\n",
    "    \n",
    "    print(\"Loading zip file...\", end=\"\")\n",
    "    # Проверяем что нет такого загруженого файла\n",
    "    if not os.path.isfile(download_path) or os.path.exists(target_folder):\n",
    "        # # Можно загрузить через requests библиотеку\n",
    "        # response = requests.get(url)\n",
    "        # open(download_path, \"wb\").write(response.content)\n",
    "        \n",
    "        # Можно загрузить через wget\n",
    "        !wget ${url} -O ${download_path}\n",
    "    print(\" --> done!\")\n",
    "    \n",
    "    print(\"Unziping...\", end=\"\")\n",
    "    # Распаковываем\n",
    "    if os.path.exists(target_folder):\n",
    "        !rm -r ${target_folder}\n",
    "    !mkdir -p ${dataset_folder}\n",
    "    !unzip -qq ${download_path} -d ${dataset_folder}\n",
    "    print(\" --> done!\")\n",
    "    \n",
    "    # Удаляем zip-файл\n",
    "    !rm ${download_path}\n",
    "    \n",
    "    # Meta + Отрисовка\n",
    "    print(f\"Provided splits: {os.listdir(target_folder)}\")\n",
    "    # Удобный способ быстро получить датасет картинок с лэйблами, если картинки разложены по папкам в формате:\n",
    "    # root_folder/label_name/img.jpg\n",
    "    # (в нашем случае нет лэйблов, но картинки разложены в таком же формате, просто вместо label_name идёт\n",
    "    #  split_name: trainA/testA/trainB/testB)\n",
    "    dataset = datasets.ImageFolder(target_folder)\n",
    "\n",
    "    inds_to_show = {i: [] for i, _ in enumerate(dataset.classes)}\n",
    "    classes_full = 0\n",
    "    for dataset_ind in range(len(dataset)):\n",
    "        _, split_ind = dataset[dataset_ind]\n",
    "        if len(inds_to_show[split_ind]) == num_images_per_split:\n",
    "            continue\n",
    "        inds_to_show[split_ind].append(dataset_ind)\n",
    "        if len(inds_to_show[split_ind]) == num_images_per_split:\n",
    "            classes_full += 1\n",
    "        if classes_full == len(dataset.classes):\n",
    "            break\n",
    "\n",
    "    for split_name in sorted(dataset.classes):\n",
    "        split_ind = dataset.class_to_idx[split_name]\n",
    "        print(f\"Split '{split_name}' of dataset '{dataset_name}'\", end=\"\")\n",
    "        split_folder = os.path.join(target_folder, split_name)\n",
    "        print(f\" --> size: {len(os.listdir(split_folder))}\")\n",
    "\n",
    "        plt.subplots(1, num_images_per_split, figsize=(5 * num_images_per_split, 5))\n",
    "        plt.suptitle(f\"{dataset_name} ~ {split_name}\", y=0.95)\n",
    "        for i, dataset_ind in enumerate(inds_to_show[split_ind]):\n",
    "            plt.subplot(1, num_images_per_split, i + 1)\n",
    "            plt.imshow(dataset[dataset_ind][0])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "    # Удаляем скачанный датасет\n",
    "    !rm -r ${target_folder}\n",
    "    \n",
    "    print(\"\\n----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f2c69-a676-4feb-88f6-1612262795f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.2 Dataset и Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a1cb2-3546-409b-8e3c-c4ce99cc62f6",
   "metadata": {},
   "source": [
    "В папке `target_folder` находятся несколько папок со сплитами для соответствующего датасета, в каждой папке сплита находятся сами `.jpg` изображения.\n",
    "\n",
    "Давайте составим их в удобном для нас виде в отдельные датасеты для каждого сплита без лэйблов.\n",
    "\n",
    "Для получения картинок можно использовать \n",
    "```python\n",
    "cv2.imread(img_path)[:, :, ::-1]  # каналы записаны в обратном порядке\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35148185-54ac-4d5f-adee-fbedcb7226ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Выбранный выше и скачанный датасет\n",
    "dataset_folder = \"/home/jupyter/datasphere/project/datasets/img2img\"\n",
    "dataset_name = \"summer2winter_yosemite\"\n",
    "target_folder = os.path.join(dataset_folder, dataset_name)\n",
    "\n",
    "# Класс для датасета изображений без лэйблов с применением трансформов\n",
    "class ImageDatasetNoLabel(Dataset):\n",
    "    def __init__(self, ...):\n",
    "        super(ImageDatasetNoLabel).__init__()\n",
    "        ...\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        ...\n",
    "\n",
    "# Удобный класс для хранения всех наших датасетов\n",
    "@dataclass\n",
    "class DatasetsClass:\n",
    "    train_a: ImageDatasetNoLabel\n",
    "    train_b: ImageDatasetNoLabel\n",
    "    test_a: ImageDatasetNoLabel\n",
    "    test_b: ImageDatasetNoLabel\n",
    "\n",
    "\n",
    "# Все датасеты без трансформов - чтобы посчитать статистики\n",
    "ds = DatasetsClass(\n",
    "    train_a=ImageDatasetNoLabel(os.path.join(target_folder, \"trainA\")),\n",
    "    train_b=ImageDatasetNoLabel(os.path.join(target_folder, \"trainB\")),\n",
    "    test_a=ImageDatasetNoLabel(os.path.join(target_folder, \"testA\")),\n",
    "    test_b=ImageDatasetNoLabel(os.path.join(target_folder, \"testB\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33116186-8715-473d-a173-b319613ab89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_channel_statistics(dataset):\n",
    "    \"\"\"\n",
    "    Функция для получения поканальных статистик (среднее и отклонение) по датасету\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return channel_mean, channel_std\n",
    "\n",
    "# Поканальное среднее и отклонение для A\n",
    "channel_mean_a, channel_std_a = get_channel_statistics(ds.train_a)\n",
    "print(channel_mean_a, channel_std_a)\n",
    "\n",
    "# Поканальное среднее и отклонение для B\n",
    "channel_mean_b, channel_std_b = get_channel_statistics(ds.train_b)\n",
    "print(channel_mean_b, channel_std_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1cb339-f365-4c3d-9f57-e6759c7c68d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция для получения train и val transform-ов, а так же функции для де-нормализации изображения\n",
    "def get_transforms(mean, std, ...):\n",
    "    train_transform = tr.Compose([\n",
    "        ...\n",
    "    ])\n",
    "    \n",
    "    test_transform = tr.Compose([\n",
    "        ...\n",
    "    ])\n",
    "    \n",
    "    def de_normalize(...):\n",
    "        ...\n",
    "    \n",
    "    return train_transform, val_transform, de_normalize\n",
    "\n",
    "\n",
    "# Ваши гиперпараметры\n",
    "hyperparams = dict(\n",
    "    ...\n",
    ")\n",
    "# transform-ы для A и B\n",
    "train_transform_a, val_transform_a, de_normalize_a = get_transforms(channel_mean_a, channel_std_a, **hyperparams)\n",
    "train_transform_b, val_transform_b, de_normalize_b = get_transforms(channel_mean_b, channel_std_b, **hyperparams)\n",
    "\n",
    "\n",
    "# Функция для визуализации transform-ов\n",
    "def show_examples(dataset, transform, de_norm, num_per_image=3, image_index=0, title=\"\"):\n",
    "    fig, ax = plt.subplots(1, 1 + num_per_image, figsize=(5 * (1 + num_per_image), 5))\n",
    "    \n",
    "    image = dataset[image_index]\n",
    "    \n",
    "    plt.suptitle(title, y=0.95)\n",
    "\n",
    "    plt.subplot(1, 1 + num_per_image, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"original\")\n",
    "\n",
    "    for i in range(num_per_image):\n",
    "        plt.subplot(1, 1 + num_per_image, i + 2)\n",
    "        plt.title(f\"#{i}\")\n",
    "        plt.imshow(de_norm(transform(image)))\n",
    "    plt.show()\n",
    "\n",
    "# Проверка на адекватность\n",
    "show_examples(ds.train_a, train_transform_a, de_normalize_a, num_per_image=4, image_index=0, title=\"A #0\")\n",
    "show_examples(ds.train_a, val_transform_a, de_normalize_a, num_per_image=1, image_index=0, title=\"A #0 - val\")\n",
    "show_examples(ds.train_a, train_transform_a, de_normalize_a, num_per_image=4, image_index=1, title=\"A #1\")\n",
    "show_examples(ds.train_a, train_transform_a, de_normalize_a, num_per_image=4, image_index=2, title=\"A #2\")\n",
    "show_examples(ds.train_b, train_transform_b, de_normalize_b, num_per_image=4, image_index=0, title=\"B #0\")\n",
    "show_examples(ds.train_b, val_transform_b, de_normalize_b, num_per_image=1, image_index=0, title=\"B #0 - val\")\n",
    "show_examples(ds.train_b, train_transform_b, de_normalize_b, num_per_image=4, image_index=1, title=\"B #1\")\n",
    "show_examples(ds.train_b, train_transform_b, de_normalize_b, num_per_image=4, image_index=2, title=\"B #2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfb1fc-9655-4fa4-9150-597c239fdfa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Все датасеты с трансформами\n",
    "ds = DatasetsClass(\n",
    "    train_a=ImageDatasetNoLabel(\n",
    "        os.path.join(target_folder, \"trainA\"),\n",
    "        transforms=train_transform_a,\n",
    "    ),\n",
    "    train_b=ImageDatasetNoLabel(\n",
    "        os.path.join(target_folder, \"trainB\"),\n",
    "        transforms=val_transform_b,\n",
    "    ),\n",
    "    test_a=ImageDatasetNoLabel(\n",
    "        os.path.join(target_folder, \"testA\"),\n",
    "        transforms=val_transform_a,\n",
    "    ),\n",
    "    test_b=ImageDatasetNoLabel(\n",
    "        os.path.join(target_folder, \"testB\"),\n",
    "        transforms=val_transform_b,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd55bf8-0618-462b-be00-f8f3f66baff3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.3 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7db4b7-6d18-405d-a36b-eadefdfef337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataLoadersClass:\n",
    "    train_a: DataLoader\n",
    "    train_b: DataLoader\n",
    "    test_a: DataLoader\n",
    "    test_b: DataLoader\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "dataloaders = DataLoadersClass(\n",
    "    train_a=DataLoader(\n",
    "        dataset=ds.train_a,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    train_b=DataLoader(\n",
    "        dataset=ds.train_b,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    test_a=DataLoader(\n",
    "        dataset=ds.test_a,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "    test_b=DataLoader(\n",
    "        dataset=ds.test_b,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f0f48-a5a0-41cc-a4d2-c0629583501c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Модель (___6 баллов___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6a57c-eb7c-4ef0-ab8b-08e659018edd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.0 Любые вспомогательные модули и классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9963ad-8c71-48ee-a1d7-400746387b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c18146-109e-4726-98c2-a08f777c7960",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1 Архитектура сети (___3 балла___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3046ff9-c360-4930-8dd0-af3e2057a8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CycleGAN(nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        super(CycleGAN, self).__init__()\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbddb5ab-ce3f-4ce2-aad3-fcc7c2a04308",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.2 Loss (___3 балла___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b60eed8-e159-46d2-91db-088aeb5f0442",
   "metadata": {},
   "source": [
    "$$ \\mathbf{L}_{\\text{cyc}} \\big( G_{A \\rightarrow B}, G_{B \\rightarrow A} \\big) = \\mathbb{E}_{a \\sim A} \\bigg( \\Big\\| G_{B \\rightarrow A} \\big( G_{A \\rightarrow B} ( a ) \\big) - a \\Big\\|_1 \\bigg) + \\mathbb{E}_{b \\sim B} \\bigg( \\Big\\| G_{A \\rightarrow B} \\big( G_{B \\rightarrow A} ( b ) \\big) - b \\Big\\|_1 \\bigg) \\longrightarrow \\min_{G}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae9661-f3fb-4dac-804f-aad4150ca045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CycleConsistencyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Функция ошибки, проверяющая что после двойного перехода через генераторы изображение не изменилось\n",
    "    \"\"\"\n",
    "    def __init__(self, ...):\n",
    "        super(CycleConsistencyLoss, self).__init__()\n",
    "        ...\n",
    "    \n",
    "    def forward(self, x, x_rec):\n",
    "        # Принимает на вход оригинальное изображение и изображение после двойного перехода\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30a504-92eb-4137-b2c9-038cf7463cbf",
   "metadata": {},
   "source": [
    "$$ \\mathbf{L}_{\\text{GAN}} \\big( G_{A \\rightarrow B}, D_{B} \\big) = \\mathbb{E}_{b \\sim B} \\log D_{B} (b) + \\mathbb{E}_{a \\sim A} \\log \\Big( 1 - D_{B} \\big( G_{A \\rightarrow B} (a) \\big) \\Big) \\longrightarrow \\min_{G} \\max_{D}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c68d84-a7ea-4e08-8f8b-1ec0adf86f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdversarialLossCE(nn.Module):\n",
    "    \"\"\"\n",
    "    Стандартная функция ошибки для minmax игры GAN-ов\n",
    "    \"\"\"\n",
    "    def __init__(self, ...):\n",
    "        super(AdversarialLossCE, self).__init__()\n",
    "        ...\n",
    "    \n",
    "    def forward(self, real_pred, fake_pred=None):\n",
    "        # Принимает на вход D_{A}(a) - real_pred и D_{A}(G(b)) - fake_pred или наоборот\n",
    "        # Может принимать только один аргумент для удобности использования в случае\n",
    "        #  обучения или генератора, или дискриминатора\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b9386-b225-47a6-822d-4ce3add97d0c",
   "metadata": {},
   "source": [
    "$$ \\mathbb{E}_{b \\sim B} \\big( D_{B} (b) - 1 \\big)^2 + \\mathbb{E}_{a \\sim A} \\Big( D_{B} \\big( G_{A \\rightarrow B} (a) \\big) \\Big)^2 \\longrightarrow \\min_{D} $$\n",
    "$$ \\mathbb{E}_{a \\sim A} \\Big( D_{B} \\big( G_{A \\rightarrow B} (a) \\big) - 1 \\Big)^2 \\longrightarrow \\min_{G} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8754b43-3e1e-44b5-9bf7-a2f8614d32c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdversarialLossMSE(nn.Module):\n",
    "    \"\"\"\n",
    "    Можно переписать не через CE, а через MSE loss на одном предсказании, помогает со стабильностью\n",
    "    \"\"\"\n",
    "    def __init__(self, ...):\n",
    "        super(AdversarialLossMSE, self).__init__()\n",
    "        ...\n",
    "    \n",
    "    def forward(self, real_pred, fake_pred=None):\n",
    "        # Принимает на вход D_{A}(a) - real_pred и D_{A}(G(b)) - fake_pred или наоборот\n",
    "        # Может принимать только один аргумент для удобности использования в случае\n",
    "        #  обучения или генератора, или дискриминатора\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb3730-eec9-4fec-9da6-5e4d07325f65",
   "metadata": {},
   "source": [
    "$$ \\mathbf{L} \\big( G_{A \\rightarrow B}, G_{B \\rightarrow A}, D_{A}, D_{B} \\big) = \\mathbf{L}_{\\text{GAN}} \\big( G_{A \\rightarrow B}, D_{B} \\big) + \\mathbf{L}_{\\text{GAN}} \\big( G_{B \\rightarrow A}, D_{A} \\big) + \\lambda \\cdot \\mathbf{L}_{\\text{cyc}} \\big( G_{A \\rightarrow B}, G_{B \\rightarrow A} \\big) \\longrightarrow \\min_{G} \\max_{D}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd9095-730a-4113-a6c9-4dc6436c2da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FullDiscriminatorLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Полная ошибка для дискриминатора\n",
    "    \"\"\"\n",
    "    def __init__(self, is_mse=True, ...):\n",
    "        super(FullDiscriminatorLoss, self).__init__()\n",
    "        self.adversarial_loss_func = AdversarialLossMSE(...) if is_mse else AdversarialLossCE(...)\n",
    "        ...\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        ...\n",
    "    ):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b58aad-8121-4d5a-941c-2e08a1e6a92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FullGeneratorLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Полная ошибка для генератора\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda_value=10., is_mse=True, ...):\n",
    "        super(FullGeneratorLoss, self).__init__()\n",
    "        self.adversarial_loss_func = AdversarialLossMSE(...) if is_mse else AdversarialLossCE(...)\n",
    "        self.cycle_consistency_loss_func = CycleConsistencyLoss(...)\n",
    "        self.lambda_value = lambda_value\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        ...\n",
    "    ):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa66c0e-6e80-42c9-a891-80087b17201a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Подготовка обучения (__2 балла__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d664b-b688-4094-b161-5cb803347cde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1 Шаг обучения дискриминатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bca09a-28ea-451c-893e-22cc840014fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_discriminators(model, opt_d, loader_a, loader_b, criterion_d):\n",
    "    model.train()\n",
    "    losses_tr = []\n",
    "    \n",
    "    iter_a = iter(loader_a)\n",
    "    iter_b = iter(loader_b)\n",
    "    batches_per_epoch = min(len(iter_a), len(iter_b))\n",
    "    \n",
    "    for _ in trange(batches_per_epoch):\n",
    "        imgs_a = next(iter_a).to(device)\n",
    "        imgs_b = next(iter_b).to(device)\n",
    "        \n",
    "        opt_d.zero_grad()\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        loss = ...\n",
    "        \n",
    "        loss.backward()\n",
    "        opt_d.step()\n",
    "        losses_tr.append(loss.item())\n",
    "    \n",
    "    return model, opt_d, np.mean(losses_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2e847-77e2-49cd-9f1d-92a84688fbc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 Шаг обучения генератора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4a00d-f1fb-4bca-a321-e21b20e02833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_generators(model, opt_g, loader_a, loader_b, criterion_g):\n",
    "    model.train()\n",
    "    losses_tr = []\n",
    "    \n",
    "    iter_a = iter(loader_a)\n",
    "    iter_b = iter(loader_b)\n",
    "    batches_per_epoch = min(len(iter_a), len(iter_b))\n",
    "    \n",
    "    for _ in trange(batches_per_epoch):\n",
    "        imgs_a = next(iter_a).to(device)\n",
    "        imgs_b = next(iter_b).to(device)\n",
    "        \n",
    "        opt_g.zero_grad()\n",
    "        \n",
    "        ...\n",
    "\n",
    "        loss = ...\n",
    "\n",
    "        loss.backward()\n",
    "        opt_g.step()\n",
    "        losses_tr.append(loss.item())\n",
    "    \n",
    "    return model, opt_g, np.mean(losses_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00dcaa-a17c-4f7c-95d8-8bb56ccac155",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.3 Шаг валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add19395-24d7-462a-afa8-19a6ee5a564e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def val(model, loader_a, loader_b, criterion_d, criterion_g):\n",
    "    model.eval()\n",
    "    \n",
    "    val_data = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        iter_a = iter(loader_a)\n",
    "        iter_b = iter(loader_b)\n",
    "        batches_per_epoch = min(len(iter_a), len(iter_b))\n",
    "\n",
    "        for _ in trange(batches_per_epoch):\n",
    "            imgs_a = next(iter_a).to(device)\n",
    "            imgs_b = next(iter_b).to(device)\n",
    "            \n",
    "            ...\n",
    "            \n",
    "            loss_d = ...\n",
    "            \n",
    "            loss_g = ...\n",
    "            \n",
    "            val_data[\"loss D\"].append(loss_d.item())\n",
    "            val_data[\"loss G\"].append(loss_g.item())\n",
    "            \n",
    "            # Оставлю для вас мой кусочек логирования для визуализации, думаю по аналогии\n",
    "            #  разберётесь что предполагалось в каких переменных\n",
    "            is_mse_pred = a_real_pred.shape[-1] == 1\n",
    "            \n",
    "            if is_mse_pred:\n",
    "                a_real_pred = a_real_pred[:, 0]\n",
    "                b_real_pred = b_real_pred[:, 0]\n",
    "                a_fake_pred = a_fake_pred[:, 0]\n",
    "                b_fake_pred = b_fake_pred[:, 0]\n",
    "            else:\n",
    "                a_real_pred = F.softmax(a_real_pred, dim=1)[:, 1]\n",
    "                b_real_pred = F.softmax(b_real_pred, dim=1)[:, 1]\n",
    "                a_fake_pred = F.softmax(a_fake_pred, dim=1)[:, 1]\n",
    "                b_fake_pred = F.softmax(b_fake_pred, dim=1)[:, 1]\n",
    "            \n",
    "            val_data[\"real pred A\"].extend(a_real_pred.cpu().detach().tolist())\n",
    "            val_data[\"real pred B\"].extend(b_real_pred.cpu().detach().tolist())\n",
    "            val_data[\"fake pred A\"].extend(a_fake_pred.cpu().detach().tolist())\n",
    "            val_data[\"fake pred B\"].extend(b_fake_pred.cpu().detach().tolist())\n",
    "        \n",
    "        val_data[\"loss D\"] = np.mean(val_data[\"loss D\"])\n",
    "        val_data[\"loss G\"] = np.mean(val_data[\"loss G\"])\n",
    "    \n",
    "    return val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f6120-2b7f-4da8-8fc0-a77788d0066b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.4 Визуализация сгенерированного"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582c1cb-0879-4883-9494-ce0256a552ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_imgs(model, num_images, loader_a, loader_b, de_norm_a, de_norm_b):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs_a = next(iter(loader_a))[:num_images].to(device)\n",
    "        imgs_b = next(iter(loader_b))[:num_images].to(device)\n",
    "        \n",
    "        fake_a = ...\n",
    "        fake_b = ...\n",
    "        rec_a = ...\n",
    "        rec_b = ...\n",
    "        \n",
    "        # Draw num_images examples for A\n",
    "        fig, ax = plt.subplots(num_images, 3, figsize=(25, 15))\n",
    "        plt.suptitle(\"Images from A\", y=0.92)\n",
    "        \n",
    "        for ind in range(num_images):\n",
    "            plt.subplot(num_images, 3, ind * 3 + 1)\n",
    "            plt.title(\"Original from A\")\n",
    "            plt.imshow(de_norm_a(imgs_a[ind], normalized=True))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "            plt.subplot(num_images, 3, ind * 3 + 2)\n",
    "            plt.title(\"Translated to B\")\n",
    "            plt.imshow(de_norm_b(fake_b[ind], normalized=True))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "            plt.subplot(num_images, 3, ind * 3 + 3)\n",
    "            plt.title(\"Reconstructed A\")\n",
    "            plt.imshow(de_norm_a(rec_a[ind], normalized=True))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        \n",
    "        # Draw num_images examples for B\n",
    "        fig, ax = plt.subplots(num_images, 3, figsize=(25, 15))\n",
    "        plt.suptitle(\"Images from B\", y=0.92)\n",
    "        \n",
    "        for ind in range(num_images):\n",
    "            plt.subplot(num_images, 3, ind * 3 + 1)\n",
    "            plt.title(\"Original from B\")\n",
    "            plt.imshow(de_norm_b(imgs_b[ind], normalized=True))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "            plt.subplot(num_images, 3, ind * 3 + 2)\n",
    "            plt.title(\"Translated to A\")\n",
    "            plt.imshow(de_norm_a(fake_a[ind], normalized=True))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "            plt.subplot(num_images, 3, ind * 3 + 3)\n",
    "            plt.title(\"Reconstructed B\")\n",
    "            plt.imshow(de_norm_b(rec_b[ind], normalized=True))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca96ce88-b19d-42f5-a499-73dc4bca3d42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.5 Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fbd13-f187-44ec-b3df-0924c4a1d864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "\n",
    "def get_model_name(chkp_folder, model_name=None):\n",
    "    # Выбираем имя чекпоинта для сохранения\n",
    "    if model_name is None:\n",
    "        if os.path.exists(chkp_folder):\n",
    "            num_starts = len(os.listdir(chkp_folder)) + 1\n",
    "        else:\n",
    "            num_starts = 1\n",
    "        model_name = f'model#{num_starts}'\n",
    "    else:\n",
    "        if \"#\" not in model_name:\n",
    "            model_name += \"#0\"\n",
    "    changed = False\n",
    "    while os.path.exists(os.path.join(chkp_folder, model_name + '.pt')):\n",
    "        model_name, ind = model_name.split(\"#\")\n",
    "        model_name += f\"#{int(ind) + 1}\"\n",
    "        changed=True\n",
    "    if changed:\n",
    "        warnings.warn(f\"Selected model_name was used already! To avoid possible overwrite - model_name changed to {model_name}\")\n",
    "    return model_name\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def learning_loop(\n",
    "    model,\n",
    "    optimizer_g,\n",
    "    g_iters_per_epoch,\n",
    "    optimizer_d,\n",
    "    d_iters_per_epoch,\n",
    "    train_loader_a,\n",
    "    train_loader_b,\n",
    "    val_loader_a,\n",
    "    val_loader_b,\n",
    "    criterion_d,\n",
    "    criterion_g,\n",
    "    de_norm_a,\n",
    "    de_norm_b,\n",
    "    scheduler_d=None,\n",
    "    scheduler_g=None,\n",
    "    min_lr=None,\n",
    "    epochs=10,\n",
    "    val_every=1,\n",
    "    draw_every=1,\n",
    "    model_name=None,\n",
    "    chkp_folder=\"./chkps\",\n",
    "    images_per_validation=3,\n",
    "    plots=None,\n",
    "    starting_epoch=0,\n",
    "):\n",
    "    model_name = get_model_name(chkp_folder, model_name)\n",
    "    \n",
    "    if plots is None:\n",
    "        plots = {\n",
    "            'train G': [],\n",
    "            'train D': [],\n",
    "            'val D': [],\n",
    "            'val G': [],\n",
    "            \"lr G\": [],\n",
    "            \"lr D\": [],\n",
    "            \"hist real A\": [],\n",
    "            \"hist gen A\": [],\n",
    "            \"hist real B\": [],\n",
    "            \"hist gen B\": [],\n",
    "        }\n",
    "\n",
    "    for epoch in np.arange(1, epochs+1) + starting_epoch:\n",
    "        print(f'#{epoch}/{epochs}:')\n",
    "\n",
    "        plots['lr G'].append(get_lr(optimizer_g))\n",
    "        plots['lr D'].append(get_lr(optimizer_d))\n",
    "        \n",
    "        # train discriminators\n",
    "        print(f\"train discriminators ({d_iters_per_epoch} times)\")\n",
    "        loss_d = []\n",
    "        for _ in range(d_iters_per_epoch):\n",
    "            model, optimizer_d, loss = train_discriminators(model, optimizer_d, train_loader_a, train_loader_b, criterion_d)\n",
    "            loss_d.append(loss)\n",
    "        plots['train D'].extend(loss_d)\n",
    "        \n",
    "        # train generators\n",
    "        print(f\"train generators ({g_iters_per_epoch} times)\")\n",
    "        loss_g = []\n",
    "        for _ in range(g_iters_per_epoch):\n",
    "            model, optimizer_g, loss = train_generators(model, optimizer_g, train_loader_a, train_loader_b, criterion_g)\n",
    "            loss_g.append(loss)\n",
    "        plots['train G'].extend(loss_g)\n",
    "\n",
    "        if not (epoch % val_every):\n",
    "            print(\"validate\")\n",
    "            val_data = val(model, val_loader_a, val_loader_b, criterion_d, criterion_g)\n",
    "            plots['val D'].append(val_data[\"loss D\"])\n",
    "            plots['val G'].append(val_data[\"loss G\"])\n",
    "            plots['hist real A'].append(val_data[\"real pred A\"])\n",
    "            plots['hist gen A'].append(val_data[\"fake pred A\"])\n",
    "            plots['hist real B'].append(val_data[\"real pred B\"])\n",
    "            plots['hist gen B'].append(val_data[\"fake pred B\"])\n",
    "            \n",
    "            # Сохраняем модель\n",
    "            if not os.path.exists(chkp_folder):\n",
    "                os.makedirs(chkp_folder)\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_d_state_dict': optimizer_d.state_dict(),\n",
    "                    'optimizer_g_state_dict': optimizer_g.state_dict(),\n",
    "                    'scheduler_d_state_dict': scheduler_d.state_dict(),\n",
    "                    'scheduler_g_state_dict': scheduler_g.state_dict(),\n",
    "                    'plots': plots,\n",
    "                },\n",
    "                os.path.join(chkp_folder, model_name + '.pt'),\n",
    "            )\n",
    "            \n",
    "            # Шедулинг\n",
    "            if scheduler_d:\n",
    "                try:\n",
    "                    scheduler_d.step()\n",
    "                except:\n",
    "                    scheduler_d.step(loss_d)\n",
    "            if scheduler_g:\n",
    "                try:\n",
    "                    scheduler_g.step()\n",
    "                except:\n",
    "                    scheduler_g.step(loss_g)\n",
    "\n",
    "        if not (epoch % draw_every):\n",
    "            clear_output(True)\n",
    "            \n",
    "            hh = 2\n",
    "            ww = 2\n",
    "            plt_ind = 1\n",
    "            fig, ax = plt.subplots(hh, ww, figsize=(25, 12))\n",
    "            fig.suptitle(f'#{epoch}/{epochs}:')\n",
    "\n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('discriminators losses')\n",
    "            d_plot_step = 1. / d_iters_per_epoch\n",
    "            plt.plot(np.arange(d_plot_step, epoch + d_plot_step, d_plot_step), plots['train D'], 'r.-', label='train', alpha=0.7)\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['val D'], 'g.-', label='val', alpha=0.7)\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "            \n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('generators losses')\n",
    "            g_plot_step = 1. / g_iters_per_epoch\n",
    "            plt.plot(np.arange(g_plot_step, epoch + g_plot_step, g_plot_step), plots['train G'], 'r.-', label='train', alpha=0.7)\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['val G'], 'g.-', label='val', alpha=0.7)\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "            \n",
    "            # plt.subplot(hh, ww, plt_ind)\n",
    "            # plt.title('learning rates')\n",
    "            # plt.plot(plots[\"lr D\"], 'b.-', label='lr discriminator', alpha=0.7)\n",
    "            # plt.plot(plots[\"lr G\"], 'm.-', label='lr generator', alpha=0.7)\n",
    "            # plt.legend()\n",
    "            # plt_ind += 1\n",
    "            \n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title(\"Discriminator A predictions\")\n",
    "            plt.hist(plots[\"hist real A\"][-1], bins=50, density=True, label=\"real\", color=\"green\", alpha=0.7)\n",
    "            plt.hist(plots[\"hist gen A\"][-1], bins=50, density=True, label=\"generated\", color=\"red\", alpha=0.7)\n",
    "            plt.xlim((-0.05, 1.05))\n",
    "            plt.xticks(ticks=np.arange(0, 1.05, 0.1))\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "            \n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title(\"Discriminator B predictions\")\n",
    "            plt.hist(plots[\"hist real B\"][-1], bins=50, density=True, label=\"real\", color=\"green\", alpha=0.7)\n",
    "            plt.hist(plots[\"hist gen B\"][-1], bins=50, density=True, label=\"generated\", color=\"red\", alpha=0.7)\n",
    "            plt.xlim((-0.05, 1.05))\n",
    "            plt.xticks(ticks=np.arange(0, 1.05, 0.1))\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            draw_imgs(model, images_per_validation, val_loader_a, val_loader_b, de_norm_a, de_norm_b)\n",
    "                \n",
    "        \n",
    "        if min_lr and get_lr(optimizer_d) <= min_lr:\n",
    "            print(f'Learning process ended with early stop for discriminator after epoch {epoch}')\n",
    "            break\n",
    "        \n",
    "        if min_lr and get_lr(optimizer_g) <= min_lr:\n",
    "            print(f'Learning process ended with early stop for generator after epoch {epoch}')\n",
    "            break\n",
    "    \n",
    "    return model, optimizer_d, optimizer_g, plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf9c46-111f-44fa-8f59-62fe73e714be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Обучение (___2 балла___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609d58f-299c-4d0f-ab45-865c23c22801",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.1 Инициализация модели и оптимайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5aa26-4de3-4c60-9feb-7869d0dff0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "def beautiful_int(i):\n",
    "    i = str(i)\n",
    "    return \".\".join(reversed([i[max(j, 0):j+3] for j in range(len(i) - 3, -3, -3)]))\n",
    "\n",
    "\n",
    "# Подсчёт числа параметров в нашей модели\n",
    "def model_num_params(model, verbose_all=True, verbose_only_learnable=False):\n",
    "    sum_params = 0\n",
    "    sum_learnable_params = 0\n",
    "    submodules = defaultdict(lambda : [0, 0])\n",
    "    for name, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        if verbose_all or (verbose_only_learnable and param.requires_grad):\n",
    "            print(\n",
    "                colored(\n",
    "                    '{: <65} ~  {: <9} params ~ grad: {}'.format(\n",
    "                        name,\n",
    "                        beautiful_int(num_params),\n",
    "                        param.requires_grad,\n",
    "                    ),\n",
    "                    {True: \"green\", False: \"red\"}[param.requires_grad],\n",
    "                )\n",
    "            )\n",
    "        sum_params += num_params\n",
    "        sm = name.split(\".\")[0]\n",
    "        submodules[sm][0] += num_params\n",
    "        if param.requires_grad:\n",
    "            sum_learnable_params += num_params\n",
    "            submodules[sm][1] += num_params\n",
    "    print(\n",
    "        f'\\nIn total:\\n  - {beautiful_int(sum_params)} params\\n  - {beautiful_int(sum_learnable_params)} learnable params'\n",
    "    )\n",
    "    \n",
    "    for sm, v in submodules.items():\n",
    "        print(\n",
    "            f\"\\n . {sm}:\\n .   - {beautiful_int(submodules[sm][0])} params\\n .   - {beautiful_int(submodules[sm][1])} learnable params\"\n",
    "        )\n",
    "    return sum_params, sum_learnable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a4a4d-e327-4d99-95c9-90a3e131604c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def create_model_and_optimizer(model_class, model_params, lr=1e-3, ..., device=device):\n",
    "    model = model_class(**model_params)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer_d = torch.optim.#{YOUR_CHOICE}(\n",
    "        ...,\n",
    "        lr,\n",
    "        ...,\n",
    "    )\n",
    "    optimizer_g = torch.optim.#{YOUR_CHOICE}(\n",
    "        ...,\n",
    "        lr,\n",
    "        ...,\n",
    "    )\n",
    "    return model, optimizer_d, optimizer_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21171e58-bece-4e19-a229-43c5e5266c28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.2 Фактическое обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31d2be-c3ec-486f-8213-e669315070c0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "results = []\n",
    "\n",
    "model, optimizer_d, optimizer_g = create_model_and_optimizer(\n",
    "    model_class = CycleGAN,\n",
    "    model_params = ...,\n",
    "    lr = 1e-3,\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "\n",
    "scheduler_d = ...\n",
    "scheduler_g = ...\n",
    "\n",
    "criterion_d = FullDiscriminatorLoss(...)\n",
    "criterion_g = FullGeneratorLoss(...)\n",
    "\n",
    "sum_params, sum_learnable_params = model_num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55437e58-9eb6-44dd-aafe-8713a34ffa0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf09fa4-54bc-4e84-9b7c-dced4ee8fe30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model, optimizer_d, optimizer_g, plots = learning_loop(\n",
    "    model = model,\n",
    "    optimizer_g = optimizer_g,\n",
    "    g_iters_per_epoch = 1,\n",
    "    optimizer_d = optimizer_d,\n",
    "    d_iters_per_epoch = 1,\n",
    "    train_loader_a = dataloaders.train_a,\n",
    "    train_loader_b = dataloaders.train_b,\n",
    "    val_loader_a = dataloaders.test_a,\n",
    "    val_loader_b = dataloaders.test_b,\n",
    "    criterion_d = criterion_d,\n",
    "    criterion_g = criterion_g,\n",
    "    scheduler_g = scheduler_g,\n",
    "    scheduler_d = scheduler_d,\n",
    "    de_norm_a = de_normalize_a,\n",
    "    de_norm_b = de_normalize_b,\n",
    "    epochs = 100,\n",
    "    min_lr = 1e-6,\n",
    "    val_every = 1,\n",
    "    draw_every = 1,\n",
    "    chkp_folder = \"./chkp\",\n",
    "    model_name = \"cycle_gan\",\n",
    "    images_per_validation=3,\n",
    "    plots=None,\n",
    "    starting_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329906b-c495-419a-bf1e-90113b3fffe7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1b890-0c4b-42d2-a598-15ffdc7f87cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model, optimizer_d, optimizer_g, plots = learning_loop(\n",
    "    model = model,\n",
    "    optimizer_g = optimizer_g,\n",
    "    g_iters_per_epoch = 1,\n",
    "    optimizer_d = optimizer_d,\n",
    "    d_iters_per_epoch = 1,\n",
    "    train_loader_a = dataloaders.train_a,\n",
    "    train_loader_b = dataloaders.train_b,\n",
    "    val_loader_a = dataloaders.test_a,\n",
    "    val_loader_b = dataloaders.test_b,\n",
    "    criterion_d = criterion_d,\n",
    "    criterion_g = criterion_g,\n",
    "    scheduler_g = scheduler_g,\n",
    "    scheduler_d = scheduler_d,\n",
    "    de_norm_a = de_normalize_a,\n",
    "    de_norm_b = de_normalize_b,\n",
    "    epochs = 100,\n",
    "    min_lr = 1e-6,\n",
    "    val_every = 1,\n",
    "    draw_every = 1,\n",
    "    chkp_folder = \"./chkp\",\n",
    "    model_name = \"cycle_gan\",\n",
    "    images_per_validation=3,\n",
    "    plots=None,\n",
    "    starting_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf4408-bcdd-4185-8f8b-f237230ab8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_a = ds.test_a[1].to(device).unsqueeze(0)\n",
    "\n",
    "plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(de_normalize_a(img_a[0]))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(de_normalize_b(model.generators[\"a_to_b\"](img_a)[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc09115-544e-4fa3-bff1-4273437a9bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_a = ds.test_a[5].to(device).unsqueeze(0)\n",
    "\n",
    "plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(de_normalize_a(img_a[0]))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(de_normalize_b(model.generators[\"a_to_b\"](img_a)[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83921df-b618-4719-b5ce-adad66184088",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ind = 1\n",
    "img_a = ds.test_a[img_ind].to(device).unsqueeze(0)\n",
    "fake_b = ...(img_a)...\n",
    "\n",
    "plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(de_normalize_a(img_a[0]))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(de_normalize_b(fake_b))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea966d-f6cc-45e5-afba-9b3bc69128c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ind = 0\n",
    "img_b = ds.test_b[img_ind].to(device).unsqueeze(0)\n",
    "fake_a = ...(img_b)...\n",
    "\n",
    "plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(de_normalize_b(img_b[0]))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(de_normalize_a(fake_a))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac1e44-761f-4af6-b605-463bd4a0e87e",
   "metadata": {},
   "source": [
    "# 5. Свои данные (___3 балла + бонусы___)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51445a7-e603-4753-b343-d538112b1484",
   "metadata": {},
   "source": [
    "В этой части необходимо выполнить следующее:\n",
    "\n",
    "1. **Создание датасетов**  \n",
    "   * Соберите один или пару небольших датасета (минимум 100 примеров, но чем больше, тем лучше).  \n",
    "   * Дайте волю фантазии, но избегайте неадекватного контента, объема данных или данных за рамками норм.  \n",
    "\n",
    "2. **Обучение CycleGAN**  \n",
    "   * Обучите модель CycleGAN для преобразования между вашим датасетом (**домен A**) и другим датасетом (**домен B**).  \n",
    "   * Второй датасет может быть вашим собственным или любым существующим  \n",
    "\n",
    "3. **Требования к сдаче**  \n",
    "   * **Архив с датасетами**:  \n",
    "     Приложите ссылку на заархивированные данные или загрузите сам архив с данными, использованные для обучения.  \n",
    "   * **Jupyter Notebook**:  \n",
    "     * Визуализируйте примеры из доменов A и B с кратким описанием идеи (например, \"преобразование эскизов в цветные рисунки\").  \n",
    "     * Добавьте код обучения модели (архитектура, гиперпараметры, функция потерь).  \n",
    "     * Покажите результаты работы модели (минимум по 5 примеров преобразований A→B и B→A).  \n",
    "   * **Hugging Face Space + Streamlit**:  \n",
    "     * Разработайте интерактивное приложение с использованием Streamlit, которое позволяет:  \n",
    "       - Загружать изображения из доменов A и B.  \n",
    "       - Отображать результаты преобразований (A→B и B→A) в реальном времени.  \n",
    "     * Выложите приложение в Hugging Face Space и приложите ссылку на него.  \n",
    "     * Убедитесь, что модель интегрирована в приложение, а проверяющие могут самостоятельно тестировать её через интерфейс.  \n",
    "\n",
    "4. **Критерии оценки**  \n",
    "   * Дополнительные баллы начисляются за:  \n",
    "     - Креативные и качественные датасеты.  \n",
    "     - Высокое качество преобразований (четкость, сохранение структуры, отсутствие артефактов).  \n",
    "     - Удобный и наглядный интерфейс Streamlit-приложения.  \n",
    "\n",
    "**Примеры идей для датасетов**:  \n",
    "- Эскизы → Реалистичные изображения.  \n",
    "- Дневные фото → Ночные фото.  \n",
    "- Картины в стиле импрессионизма → фотореализм.  \n",
    "\n",
    "**Важно**:  \n",
    "- Проверяющий будет оценивать работу через ваше Streamlit-приложение. Убедитесь, что инференс работает стабильно.  \n",
    "- Если модель слишком велика для деплоя, используйте оптимизацию.  \n",
    "\n",
    "___Удачи!___ 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e2048-cd3c-4865-be1b-2f48937711c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
