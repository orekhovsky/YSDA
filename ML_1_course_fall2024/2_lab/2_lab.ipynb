{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List\n",
    "\n",
    "import sklearn.base\n",
    "\n",
    "seed = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 81 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MS_SubClass         2930 non-null   object \n",
      " 1   MS_Zoning           2930 non-null   object \n",
      " 2   Lot_Frontage        2930 non-null   int64  \n",
      " 3   Lot_Area            2930 non-null   int64  \n",
      " 4   Street              2930 non-null   object \n",
      " 5   Alley               2930 non-null   object \n",
      " 6   Lot_Shape           2930 non-null   object \n",
      " 7   Land_Contour        2930 non-null   object \n",
      " 8   Utilities           2930 non-null   object \n",
      " 9   Lot_Config          2930 non-null   object \n",
      " 10  Land_Slope          2930 non-null   object \n",
      " 11  Neighborhood        2930 non-null   object \n",
      " 12  Condition_1         2930 non-null   object \n",
      " 13  Condition_2         2930 non-null   object \n",
      " 14  Bldg_Type           2930 non-null   object \n",
      " 15  House_Style         2930 non-null   object \n",
      " 16  Overall_Qual        2930 non-null   object \n",
      " 17  Overall_Cond        2930 non-null   object \n",
      " 18  Year_Built          2930 non-null   int64  \n",
      " 19  Year_Remod_Add      2930 non-null   int64  \n",
      " 20  Roof_Style          2930 non-null   object \n",
      " 21  Roof_Matl           2930 non-null   object \n",
      " 22  Exterior_1st        2930 non-null   object \n",
      " 23  Exterior_2nd        2930 non-null   object \n",
      " 24  Mas_Vnr_Type        1155 non-null   object \n",
      " 25  Mas_Vnr_Area        2930 non-null   int64  \n",
      " 26  Exter_Qual          2930 non-null   object \n",
      " 27  Exter_Cond          2930 non-null   object \n",
      " 28  Foundation          2930 non-null   object \n",
      " 29  Bsmt_Qual           2930 non-null   object \n",
      " 30  Bsmt_Cond           2930 non-null   object \n",
      " 31  Bsmt_Exposure       2930 non-null   object \n",
      " 32  BsmtFin_Type_1      2930 non-null   object \n",
      " 33  BsmtFin_SF_1        2930 non-null   int64  \n",
      " 34  BsmtFin_Type_2      2930 non-null   object \n",
      " 35  BsmtFin_SF_2        2930 non-null   int64  \n",
      " 36  Bsmt_Unf_SF         2930 non-null   int64  \n",
      " 37  Total_Bsmt_SF       2930 non-null   int64  \n",
      " 38  Heating             2930 non-null   object \n",
      " 39  Heating_QC          2930 non-null   object \n",
      " 40  Central_Air         2930 non-null   object \n",
      " 41  Electrical          2930 non-null   object \n",
      " 42  First_Flr_SF        2930 non-null   int64  \n",
      " 43  Second_Flr_SF       2930 non-null   int64  \n",
      " 44  Low_Qual_Fin_SF     2930 non-null   int64  \n",
      " 45  Gr_Liv_Area         2930 non-null   int64  \n",
      " 46  Bsmt_Full_Bath      2930 non-null   int64  \n",
      " 47  Bsmt_Half_Bath      2930 non-null   int64  \n",
      " 48  Full_Bath           2930 non-null   int64  \n",
      " 49  Half_Bath           2930 non-null   int64  \n",
      " 50  Bedroom_AbvGr       2930 non-null   int64  \n",
      " 51  Kitchen_AbvGr       2930 non-null   int64  \n",
      " 52  Kitchen_Qual        2930 non-null   object \n",
      " 53  TotRms_AbvGrd       2930 non-null   int64  \n",
      " 54  Functional          2930 non-null   object \n",
      " 55  Fireplaces          2930 non-null   int64  \n",
      " 56  Fireplace_Qu        2930 non-null   object \n",
      " 57  Garage_Type         2930 non-null   object \n",
      " 58  Garage_Finish       2930 non-null   object \n",
      " 59  Garage_Cars         2930 non-null   int64  \n",
      " 60  Garage_Area         2930 non-null   int64  \n",
      " 61  Garage_Qual         2930 non-null   object \n",
      " 62  Garage_Cond         2930 non-null   object \n",
      " 63  Paved_Drive         2930 non-null   object \n",
      " 64  Wood_Deck_SF        2930 non-null   int64  \n",
      " 65  Open_Porch_SF       2930 non-null   int64  \n",
      " 66  Enclosed_Porch      2930 non-null   int64  \n",
      " 67  Three_season_porch  2930 non-null   int64  \n",
      " 68  Screen_Porch        2930 non-null   int64  \n",
      " 69  Pool_Area           2930 non-null   int64  \n",
      " 70  Pool_QC             2930 non-null   object \n",
      " 71  Fence               2930 non-null   object \n",
      " 72  Misc_Feature        106 non-null    object \n",
      " 73  Misc_Val            2930 non-null   int64  \n",
      " 74  Mo_Sold             2930 non-null   int64  \n",
      " 75  Year_Sold           2930 non-null   int64  \n",
      " 76  Sale_Type           2930 non-null   object \n",
      " 77  Sale_Condition      2930 non-null   object \n",
      " 78  Sale_Price          2930 non-null   int64  \n",
      " 79  Longitude           2930 non-null   float64\n",
      " 80  Latitude            2930 non-null   float64\n",
      "dtypes: float64(2), int64(33), object(46)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (2344, 80) (2344,)\n",
      "Test : (586, 80) (586,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_column = \"Sale_Price\"\n",
    "np.random.seed(seed)\n",
    "\n",
    "test_size = 0.2\n",
    "data_train, data_test, Y_train, Y_test = train_test_split(\n",
    "    data[data.columns.drop(\"Sale_Price\")],\n",
    "    np.array(data[\"Sale_Price\"]),\n",
    "    test_size=test_size,\n",
    "    random_state=seed)\n",
    "\n",
    "print(f\"Train : {data_train.shape} {Y_train.shape}\")\n",
    "print(f\"Test : {data_test.shape} {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous : 34, Categorical : 46\n"
     ]
    }
   ],
   "source": [
    "continuous_columns = [key for key in data.keys() if data[key].dtype in (\"int64\", \"float64\")]\n",
    "categorical_columns = [key for key in data.keys() if data[key].dtype == \"object\"]\n",
    "\n",
    "continuous_columns.remove(target_column)\n",
    "\n",
    "print(f\"Continuous : {len(continuous_columns)}, Categorical : {len(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lot_Frontage',\n",
       " 'Lot_Area',\n",
       " 'Year_Built',\n",
       " 'Year_Remod_Add',\n",
       " 'Mas_Vnr_Area',\n",
       " 'BsmtFin_SF_1',\n",
       " 'BsmtFin_SF_2',\n",
       " 'Bsmt_Unf_SF',\n",
       " 'Total_Bsmt_SF',\n",
       " 'First_Flr_SF',\n",
       " 'Second_Flr_SF',\n",
       " 'Low_Qual_Fin_SF',\n",
       " 'Gr_Liv_Area',\n",
       " 'Bsmt_Full_Bath',\n",
       " 'Bsmt_Half_Bath',\n",
       " 'Full_Bath',\n",
       " 'Half_Bath',\n",
       " 'Bedroom_AbvGr',\n",
       " 'Kitchen_AbvGr',\n",
       " 'TotRms_AbvGrd',\n",
       " 'Fireplaces',\n",
       " 'Garage_Cars',\n",
       " 'Garage_Area',\n",
       " 'Wood_Deck_SF',\n",
       " 'Open_Porch_SF',\n",
       " 'Enclosed_Porch',\n",
       " 'Three_season_porch',\n",
       " 'Screen_Porch',\n",
       " 'Pool_Area',\n",
       " 'Misc_Val',\n",
       " 'Mo_Sold',\n",
       " 'Year_Sold',\n",
       " 'Longitude',\n",
       " 'Latitude']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы решили делать преобразование данных, которое состоит в:\n",
    "\n",
    "- сохранении лишь непрерывных фичей;\n",
    "- нормализации этих фичей (давайте остановимся на [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))\n",
    "\n",
    "В этом пункте вам нужно будет сделать класс такой предобработки данных, причём оформим мы его в виде класса с интерфейсом fit-transform.\n",
    "\n",
    "Несколько важных соображений:\n",
    "\n",
    "1. В прошлой лабораторной метод fit у нас ничего не возвращал, но правильнее сделать так, чтобы метод fit возвращал сам класс. В частности, это позволит нам писать model = model.fit().\n",
    "\n",
    "2. Первоначальный анализ данных удобно делать, когда они лежат в pd.DataFrame, т к у этого класса много методов, которые малым количеством телодвижений позволяют считать статистики и строить графики. Модели же проще учить, когда данные лежат в np.array, потому большое количество библиотек, где реализованы методы машинного обучения совместимы именно с numpy. Поэтому сделайте так, чтобы метод transform получал на вход pd.Dataframe, а возвращал np.array.\n",
    "\n",
    "3. В sklearn есть классы, от которых можно отнаследоваться, чтобы сделать класс с [fit-predict](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin) или [fit-transform](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) интерфейсом. Это очень полезно, т к позволит вам в дальнейшем пользоваться методами [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) и подобными. В этом пункте отнаследуйтесь от второго.\n",
    "\n",
    "4. У метода __init__ должен быть параметр ```needed_columns=None```. Туда передается список колонок, которые нужно взять из датафрейме. Делать это надо в ```fit``` и ```transform```. В случае если если он равен None, то класс оставляет все колонки из исходного набора данных.\n",
    "\n",
    "5. Обратите внимание, что достаточно реализовать `fit` и `transform`, а метод `fit_transform` из них слепит родительский класс.\n",
    "\n",
    "**Готовый препроцессор вам нужно будет сдать в Контест**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class BaseDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
    "        self.needed_columns = needed_columns\n",
    "        self.scaler = StandardScaler(ddof=0)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if self.needed_columns is not None:\n",
    "            data = data[self.needed_columns]\n",
    "        self.scaler.fit(data)\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame):\n",
    "        if self.needed_columns is not None:\n",
    "            data = data[self.needed_columns]\n",
    "        self.scaler.transform(data)\n",
    "        data = data.to_numpy()\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Правильный вариант\n",
    "from typing import Optional, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class BaseDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        :param needed_columns: список колонок для использования. Если None, используются все колонки.\n",
    "        \"\"\"\n",
    "        self.needed_columns = needed_columns\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame, *args):\n",
    "        \"\"\"\n",
    "        Подготавливает класс для последующих преобразований.\n",
    "        :param data: pd.DataFrame с данными.\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        # Если нужны конкретные колонки, берем только их\n",
    "        if self.needed_columns is not None:\n",
    "            data = data[self.needed_columns]\n",
    "        \n",
    "        # Сохраняем только числовые фичи (непрерывные)\n",
    "        self.continuous_columns = data.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        # Подгоняем scaler только на этих фичах\n",
    "        self.scaler.fit(data[self.continuous_columns])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Преобразует данные для использования в регрессорах.\n",
    "        :param data: pd.DataFrame с данными.\n",
    "        :return: np.array с нормализованными фичами.\n",
    "        \"\"\"\n",
    "        # Если нужны конкретные колонки, берем только их\n",
    "        if self.needed_columns is not None:\n",
    "            data = data[self.needed_columns]\n",
    "        \n",
    "        # Трансформируем только числовые фичи\n",
    "        data_transformed = self.scaler.transform(data[self.continuous_columns])\n",
    "        \n",
    "        return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = BaseDataPreprocessor(needed_columns=continuous_columns)\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия\n",
    "Давайте получим базовое решение (бейзлайн), чтобы потом с ним можно было сравниваться.\n",
    "\n",
    "Обучите линейную регрессию на обучающей выборке (которую мы подвергли преобразованию BaseDataPreprocessor). В библиотеке Sklearn есть релизация [без регуляризации](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression), [с L2-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) и [с L1-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso).\n",
    "\n",
    "Начнём с обычной регрессии. Получите предсказания на тестовых данных и оцените на них качество модели. В качестве метрики оценки качества возьмите [средний модуль отклонения](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (mean absolute error, MAE). Как вам кажется, насколько хорошей вышла модель?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 23828.097175932493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model = LinearRegression().fit(X_train, Y_train)\n",
    "lin_reg_pred = model.predict(X_test)\n",
    "print('MAE:', mean_absolute_error(Y_test, lin_reg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 23816.340137451196\n"
     ]
    }
   ],
   "source": [
    "lin_reg_l2_pred = Ridge(alpha=10).fit(X_train, Y_train).predict(X_test)\n",
    "print('MAE:', mean_absolute_error(Y_test, lin_reg_l2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 23816.93165497276\n"
     ]
    }
   ],
   "source": [
    "lin_reg_l1_pred = Lasso(alpha=10).fit(X_train, Y_train).predict(X_test)\n",
    "print('MAE:', mean_absolute_error(Y_test, lin_reg_l1_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор метрики\n",
    "\n",
    "Средний модуль ошибки (MAE) — в целом довольно хорошая метрика для задачи регрессии, потому что ее довольно легко проинтерпретировать. Но с ней есть одна проблема: ошибиться на $ 10\\:000 $ USD в предсказании цены квартиры стоимостью $ 100\\:000 $ USD страшнее чем допустить такую ошибку в предсказании цены жилья за $ 700\\:000 $ USD. Иными словами более показательной метрикой будет не абсолютная  ошибка $ e_i = |y_i - \\widehat{y_i}|$, а логарифм относительной ошибки $e_i = \\log \\frac{y_i}{\\widehat{y_i}} $. Также давайте обычное усреднение по всем примерам в тестовой выборке заменим на среднеквадратичное $ \\frac{1}{n} \\sum_{i=1}^{n} {e_i} \\longrightarrow \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}{e_i^2}}$. Итоговая метрика получается равной:\n",
    "\n",
    "$$\n",
    "Metric = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{n} \\left[\\log y_i - \\log \\widehat{y_i}\\right]^2}\n",
    "$$\n",
    "\n",
    "Логично? Да. Но возникает еще одна проблема. Логарифм нельзя брать от отрицательного числа. Бороться с этим можно двумя способами.\n",
    "- Случай когда отрицательное число затисалось в target-ax не очень разумен, т. к. цена на дом не может быть отрицательной. В этом случае стоит кинуть ошибку, чтобы пользователь этой функции еще раз перепроверил правильные ли таргеты он подает.\n",
    "- В целом, у нас нет гарантий того, что наша модель (например линейная) предсказывает только положительные числа. Брать логарифм от отрицательного числа не получится, но качество такой модели все еще надо оценить. Давайте все предсказания, которые меньше некоторого порога $ a_{min} $, заменять этим порогом (то есть $ \\widehat{y_i} := \\max(\\widehat{y_i}, a_{min}) $), после чего подавать их в метрику. Для прохождения тестов возьмите $ a_{min} = 1 $.\n",
    "\n",
    "**2. (1 балл) Реализуйте эту метрику и сдайте в контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def root_mean_squared_logarithmic_error(y_true, y_pred):\n",
    "\tif np.any(y_true < 0):\n",
    "\t\twarnings.warn(\"y_true contains negative values, which is not allowed\", RuntimeWarning)\n",
    "\tif np.any(y_pred < 0):\n",
    "\t\twarnings.warn(\"y_pred contains negative values, which is not allowed\", RuntimeWarning)\n",
    "\tfirst_log = np.log(y_true)\n",
    "\tsecond_log = np.log(np.clip(y_pred, 1,None))\n",
    "\treturn np.sqrt(np.mean(np.square(first_log - second_log)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19495529943282977\n"
     ]
    }
   ],
   "source": [
    "print(root_mean_squared_logarithmic_error(Y_test, lin_reg_l1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.036317960415944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_888\\3703334710.py:8: RuntimeWarning: y_pred contains negative values, which is not allowed\n",
      "  warnings.warn(\"y_pred contains negative values, which is not allowed\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Сгенерируем отрицательные числа чтобы посмотреть как работает функция с отрицательными значениями\n",
    "np.random.seed(seed)\n",
    "Y_test_neg = np.random.randint(-1000, 0, size=Y_test.shape)\n",
    "\n",
    "print(root_mean_squared_logarithmic_error(Y_test, Y_test_neg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логарифмирование таргета \n",
    "\n",
    "Вообще идея с логарифмированием таргета довольно хороша для этой задачи. Давайте посмотрим на распределение обычных и логарифмированных таргетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_distribution(Y_train, Y_test, ax, n_bins=20):\n",
    "    ax.hist(Y_train, bins=n_bins, label=\"train\", color=\"red\", alpha=1, density=True)\n",
    "    ax.hist(Y_test, bins=n_bins, label=\"test\", color=\"blue\", alpha=1, density=True)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "\n",
    "\n",
    "def plot_both_distributions(Y_train, Y_test):\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, figsize=(15, 6))\n",
    "\n",
    "    plot_target_distribution(Y_train, Y_test, ax=ax0)\n",
    "    ax0.set_title(\"Standard\")\n",
    "\n",
    "    plot_target_distribution(np.log(Y_train), np.log(Y_test), ax=ax1)\n",
    "    ax1.set_title(\"Logarithmic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_both_distributions(Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, если прологарифмировать таргеты, то их распределение станет более похоже на гауссовское. Интуиция подсказывает, что линейная регрессия с функцией потерь MSE должна лучше учиться на таких таргетах.\n",
    "\n",
    "Попробуйте написать класс, который во время обучения логарифмирует таргет, а во время предсказания — наоборот, экспоненциирует. После чего обучите оба метода на обучающих данных и сравните значения метрик MAE и MSLE на тесте.\n",
    "\n",
    "Что должно быть в этом классе:\n",
    "- Класс должен называться ```ExponentialLinearRegression```\n",
    "- Класс должен иметь такой же fit-predict интерфейс, как и было до этого. На вход он получает оригинальные X и Y, а уже внутри происходит логарифмирование или экспоненциирование.\n",
    "- Внутри этой модели будет работать [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). Хочется, чтобы этому классу можно было передавать аргументы инициализации с помощью *args и **kwargs\n",
    "- Чтобы потом этот класс можно было использовать в [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) в следующих пунктах, у него должны быть реализованы 5 методов\n",
    "    1. ```__init__(self, *args, **kwargs)``` &mdash; все полученные аргументы передаются дальше в Ridge.\n",
    "    2. ```fit(self, X, Y)``` &mdash; обучает класс, возвращает self.\n",
    "    3. ```predict(self, X)``` &mdash; делает предсказание.\n",
    "    4. ```get_params(deep=True)``` &mdash; возвращает dict с параметрами модели. Больше подробностей [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "    5. ```set_params(**params)``` &mdash; передает нужные параметры в модель. Больше подробносте [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "- Есть два подхода к тому как сделать все нужные методы:\n",
    "    - Отнаследоваться от класса Ridge и переопределить методы fit и predict, внутри вызывая super() от отцовского класса.\n",
    "    - Отнаследоваться от класса RegressorMixin и внутренним атрибутом класса сделать Ridge. Тогда все методы нужно будет писать руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class ExponentialLinearRegression(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Инициализируем Ridge с переданными аргументами\n",
    "        self.ridge = Ridge(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # Логарифмируем таргет перед обучением\n",
    "        self.ridge.fit(X, np.log(Y))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Экспоненциируем предсказания\n",
    "        log_preds = self.ridge.predict(X)\n",
    "        return np.exp(log_preds)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        # Возвращаем параметры Ridge\n",
    "        return self.ridge.get_params(deep=deep)\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        # Устанавливаем параметры Ridge\n",
    "        self.ridge.set_params(**params)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  : Classic : 23821.977761006816  Exponential : 26818.69978654439\n",
      "MSLE : Classic : 0.1950062123328133 Exponential : 0.21601027716185428\n"
     ]
    }
   ],
   "source": [
    "classic_regressor = Ridge()\n",
    "exponential_regressor = ExponentialLinearRegression()\n",
    "\n",
    "classic_regressor.fit(X_train, Y_train)\n",
    "exponential_regressor.fit(X_train, Y_train)\n",
    "\n",
    "classic_prediction = classic_regressor.predict(X_test)\n",
    "exponential_prediction = exponential_regressor.predict(X_test)\n",
    "\n",
    "print(f\"MAE  : Classic : {mean_absolute_error(Y_test, classic_prediction)}  Exponential : {mean_absolute_error(Y_test, exponential_prediction)}\")\n",
    "print(f\"MSLE : Classic : {root_mean_squared_logarithmic_error(Y_test, classic_prediction)} Exponential : {root_mean_squared_logarithmic_error(Y_test, exponential_prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Кроссвалидация и МАЕ\n",
    "\n",
    "Введите число, округлённое до целого:\n",
    "- MAE обычной линейной регрессии (без регуляризации и с дефолтными параметрами) на объединении обучающей и тестовой выборок, посчитанную по кросс-валидации.\n",
    "В качестве параметра cv в кросс-валидации вам нужно указать KFold(n_splits=5, shuﬄe=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE, округлённое до целого: 23225\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Создаём объект кросс-валидатора KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Создаем модель линейной регрессии\n",
    "classic_regressor = LinearRegression()\n",
    "\n",
    "# Объединяем данные (предположим, что X_train, X_test, Y_train, Y_test — массивы NumPy)\n",
    "X_all = np.concatenate((X_train, X_test), axis=0)\n",
    "y_all = np.concatenate((Y_train, Y_test), axis=0)\n",
    "\n",
    "# Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = cross_validate(\n",
    "    estimator=classic_regressor,  # модель\n",
    "    X=X_all,  # матрица наблюдений X\n",
    "    y=y_all,  # вектор ответов y\n",
    "    cv=kf,  # кросс-валидатор\n",
    "    scoring='neg_mean_absolute_error',  # метрика\n",
    "    return_train_score=True  # подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "\n",
    "# Извлекаем метрики по MAE (они отрицательные из-за 'neg_mean_absolute_error')\n",
    "mae_scores = -cv_metrics['test_score']\n",
    "\n",
    "# Средний MAE\n",
    "mean_mae = np.mean(mae_scores)\n",
    "\n",
    "# Округляем до целого\n",
    "rounded_mae = round(mean_mae)\n",
    "\n",
    "print(\"MAE, округлённое до целого:\", rounded_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Линейная модель своими руками\n",
    "\n",
    "В этом разделе вы напишете собственный класс линейной модели, чтобы лучше разобраться, как работает обучение с помощью SGD.\n",
    "\n",
    "Линейная модель делает предсказание по такой формуле:\n",
    "$$\n",
    "\\widehat{y}(x) = x^T \\widehat{\\theta}\n",
    "$$\n",
    "Здесь $\\widehat{\\theta}$ &mdash; обучаемые параметры, $x$ &mdash; вектор фичей данного примера.\n",
    "Оценка $\\widehat{\\theta}$ находятся из задачи минимизации лосс функции:\n",
    "\n",
    "$$\n",
    "F(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(Y_i - x_i^T \\theta\\right)^2 + \\lambda \\theta^T\\theta \\longrightarrow \\min_{\\theta \\in \\mathbb{R}^d}\n",
    "$$\n",
    "\n",
    "Эту задачу минимизации будем решать градиентным спуском. Для этого реализуем этот метод ввиде класса с методами fit-predict.\n",
    "Что в нем должно быть:\n",
    "1. Класс должен называться ```SGDLinearRegressor```\n",
    "2. Класс должен быть отнаследован от sklearn-овского класса [RegressorMixin](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html)\n",
    "3. Класс должен инициализироваться со следующими гиперпараметрами:\n",
    "\n",
    "    * ```lr``` — learning rate. Длина шага градиентного спуска\n",
    "\n",
    "    * ```regularization``` — коэффициент $\\lambda$ из формулы выше\n",
    "    \n",
    "    * ```delta_converged``` — устанавливает условие окончание обучение. В тот момент когда норма разности весов на соседних шагах градиентного спуска меньше чем ```delta_converged``` метод прекращает обновлять веса\n",
    "    \n",
    "    * ```max_steps``` — максимальное число шагов градиентного спуска\n",
    "    \n",
    "    * ```batch_size``` — размер батча\n",
    "\n",
    "4. Реализуйте **стохастический** градиентный спуск. На каждом шагу градиентного спуска должен формироваться батч размера ```batch_size``` из матрицы признаков. Это нужно для того чтобы метод быстрее сходился. Батч может выбираться случайно на каждом шаге градиентного спуска, либо каждую эпоху можно перемешивать трейн выборку и итерироваться батчами по ней.\n",
    "\n",
    "\n",
    "Обратите внимание при реализации SGD на следующие моменты (частые ошибки):\n",
    "* не перепутайте, какие коэффициенты в SGD стоят при самой функции потерь, а какие — при регуляризационном члене\n",
    "* для остановки нужно сравнивать норму, а не ее квадрат\n",
    "* для правильного решения нужно не итерироваться по батчу,  а перемножать матрицы (иначе не зайдет по TL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDLinearRegressor(RegressorMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=0.01,\n",
    "        regularization=1.,\n",
    "        delta_converged=1e-2,\n",
    "        max_steps=1000,\n",
    "        batch_size=64,\n",
    "    ):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.max_steps = max_steps\n",
    "        self.delta_converged = delta_converged\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        # <Your code here>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Неправильный вариант\n",
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "class SGDLinearRegressor(RegressorMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=0.01,\n",
    "        regularization=1.,\n",
    "        delta_converged=1e-2,\n",
    "        max_steps=1000,\n",
    "        batch_size=64,\n",
    "    ):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.max_steps = max_steps\n",
    "        self.delta_converged = delta_converged\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.W = None  # веса модели\n",
    "        self.b = None  # смещение модели\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.W = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for step in range(self.max_steps):\n",
    "            # Случайно перемешиваем данные для стохастического градиентного спуска\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            Y_shuffled = Y[indices]\n",
    "\n",
    "            # Итерация по батчам\n",
    "            for i in range(0, n_samples, self.batch_size):\n",
    "                X_batch = X_shuffled[i:i + self.batch_size]\n",
    "                Y_batch = Y_shuffled[i:i + self.batch_size]\n",
    "\n",
    "                # Предсказание\n",
    "                Y_pred = np.dot(X_batch, self.W) + self.b\n",
    "\n",
    "                # Вычисление градиентов\n",
    "                error = Y_pred - Y_batch\n",
    "                grad_W = (2 / len(Y_batch)) * np.dot(X_batch.T, error) + 2 * self.regularization * self.W\n",
    "                grad_b = (2 / len(Y_batch)) * np.sum(error)\n",
    "\n",
    "                # Обновление весов\n",
    "                W_old = self.W.copy()\n",
    "                self.W -= self.lr * grad_W\n",
    "                self.b -= self.lr * grad_b\n",
    "\n",
    "                # Проверка сходимости\n",
    "                if np.linalg.norm(self.W - W_old) < self.delta_converged:\n",
    "                    return self\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.W) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Правильный вариант\n",
    "class SGDLinearRegressor(RegressorMixin):\n",
    "    def __init__(self,\n",
    "                 lr=0.01, regularization=1., delta_converged=1e-3, max_steps=1000,\n",
    "                 batch_size=64):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.max_steps = max_steps\n",
    "        self.delta_converged = delta_converged\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        n_samples, n_features = X.shape # n_samples - количество строк (количество примеров); n_features - количество признаков\n",
    "        # Инициализация весов и смещения\n",
    "        self.W = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for step in range(self.max_steps):\n",
    "            # Перемешиваем данные для создания случайных батчей\n",
    "            indices = np.arange(n_samples) # аналог функции 'range' только создается одномерный массив \n",
    "            np.random.shuffle(indices) # перемешаем индексы\n",
    "            X_shuffled = X[indices]\n",
    "            Y_shuffled = Y[indices]\n",
    "\n",
    "            for start_idx in range(0, n_samples, self.batch_size): # от 0 до n_samples с шагом batch_size\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X_shuffled[start_idx:end_idx]\n",
    "                Y_batch = Y_shuffled[start_idx:end_idx]\n",
    "\n",
    "                # Предсказание\n",
    "                Y_pred = np.dot(X_batch, self.W) + self.b\n",
    "                \n",
    "                # Вычисление градиентов\n",
    "                error = Y_pred - Y_batch\n",
    "                grad_w = (2 / self.batch_size) * np.dot(X_batch.T, error) + 2 * self.regularization * self.W\n",
    "                grad_b = (2 / self.batch_size) * np.sum(error)\n",
    "\n",
    "                # Обновление весов и смещения\n",
    "                self.W -= self.lr * grad_w\n",
    "                self.b -= self.lr * grad_b\n",
    "\n",
    "            # Проверка условия остановки\n",
    "            if np.linalg.norm(self.lr * grad_w) < self.delta_converged:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586,) (586,)\n",
      "MAE :  25724.050949730074\n",
      "Mean log :  0.18863716956644616\n"
     ]
    }
   ],
   "source": [
    "# Check yourself\n",
    "model = SGDLinearRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "print(Y_test.shape, prediction.shape)\n",
    "print(\"MAE : \", mean_absolute_error(Y_test, prediction))\n",
    "print(\"Mean log : \", root_mean_squared_logarithmic_error(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Категориальные признаки\n",
    "\n",
    "В самом начале ноутбука мы отбросили категориальные фичи, хотя они могут помочь нам сделать модель лучше. Давайте же научимся ими пользоваться.\n",
    "\n",
    "Самый простой подход — это закодировать значения категориального признака числами, скажем, от $0$ до $C-1$, где $C$ — количество значений категориального признака. Иногда это может сработать, но для этого нужно, чтобы между значениями признака были определены отношения больше/меньше (такие признаки называются _ординальными_), причём соотношения между значениями должны быть более-менее линейными. В целом, не очень частая ситуация, поэтому так мы делать не будем.\n",
    "\n",
    "Вместо этого мы будем использовать OneHotEncoding. Пусть некоторая категориальная фича имеет $C$ уникальных значений. Давайте эту фичу закодируем в виде $C$ столбцов, каждый из которых соответствует некоторому уникальному значению категориальной фичи. Для каждого элемента выборки будем класть единичку в столбец, соответствующий этой фиче, и нолики в остальные.\n",
    "\n",
    "У этого метода есть недостаток. Если категориальная фича принимает слишком много значений, то вы нагенерируете много новых столбцов, каждый из которых будет содержать мало информации. Из-за них моделька может переобучиться.\n",
    "\n",
    "Этот метод имплементирован [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). У него есть пара важных гиперпараметров, которые стоит упомянуть:\n",
    "- ```handle_unknown``` &mdash; управляет обработкой незнакомых категорий на этапе `transform`. Число уникальных значений (и число столбцов) настраивается на обучающей выборке, и при дальнейшем применении может появиться значение, которого ещё не было. Если указать ```handle_unknown=\"ignore\"```, все поля для такого объекта будут заполнены нулями.\n",
    "- ```drop``` &mdash; если делать one-hot-encoding так как это описано выше, то сумма всех столбцов, соответствующих значениям категориальной фичи, будет равна единичному вектору. А такой вектор уже есть (он соответствует свободному члену). То есть признаки становятся линейно зависимыми, и это сломает процесс обучения линейной модели. Поэтому есть смысл для каждой фичи отбрасывать одну из получившихся колонок (```drop=\"first\"```) или хотя бы делать это только для бинарных фичей (```drop=\"if_binary\"```)\n",
    "\n",
    "В этом пункте вам надо еще раз предобработать данные, добавив в них часть категориальных фичей, закодированных OneHotEncoding-ом. После этого обучите классификатор заново и выбейте лучшую метрику на тестовой выборке. А именно, мы добавим фичи \"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\". Используйте значение параметра handle_unknown=\"ignore\".\n",
    "\n",
    "*Замечание.* На практике в некоторых версиях scikit-learn есть проблема с совместимостью `handle_unknown=\"ignore\"` и `drop=\"first\"` одновременно, поэтому вторым можно пожертвовать.\n",
    "\n",
    "Класс будет наследоваться от BaseDataPreprocessor, так что в него можно будет передавать нужные для BaseDataPreprocessor параметры. Также это позволит не переписывать заново то, что происходит в базовом классе, а просто взывать к ним с помощью конструкции `super`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "interesting_columns = [\"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\"]\n",
    "\n",
    "class OneHotPreprocessor(BaseDataPreprocessor):\n",
    "    def __init__(self, columns_to_encode: List[str], continue_columns: Optional[List[str]]):\n",
    "        super().__init__(needed_columns=continue_columns)\n",
    "        self.columns_to_encode = columns_to_encode\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    def fit(self, data: pd.DataFrame, *args):\n",
    "        # Fit the encoder only on the specified columns\n",
    "        self.encoder.fit(data[self.columns_to_encode])\n",
    "        # Fit the scaler using the parent class method \n",
    "        super().fit(data, *args) # Это для масштабирования числовых признаков.\n",
    "                                 # В родительском методе fit у BaseDataPreprocessor есть фильтрация needed_columns,\n",
    "                                 # так что ничего страшного в том, что мы передаем все данные (категориальные + числовые)\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        # One-hot encode the specified columns\n",
    "        data_encoded = self.encoder.transform(data[self.columns_to_encode])\n",
    "        # Scale the other columns using the parent class method\n",
    "        data_scaled = super().transform(data) # Тут так же в методе transform у родительского класса BaseDataPreprocessor есть фильтрация needed_columns\n",
    "        # Concatenate the encoded and scaled data\n",
    "        return np.concatenate((data_encoded.toarray(), data_scaled), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE : 0.21601027716185428\n",
      "RMSLE (One hot encoder) : 0.1856098280071807\n"
     ]
    }
   ],
   "source": [
    "# Без кодирования\n",
    "model = ExponentialLinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "base_prediction = model.predict(X_test)\n",
    "print(\"RMSLE :\", root_mean_squared_logarithmic_error(Y_test, base_prediction))\n",
    "\n",
    "# C one hot кодированием\n",
    "ohe_preprocessor = OneHotPreprocessor(interesting_columns, continuous_columns)\n",
    "X_train_ohe = ohe_preprocessor.fit_transform(data_train)\n",
    "X_test_ohe = ohe_preprocessor.transform(data_test)\n",
    "\n",
    "model = ExponentialLinearRegression()\n",
    "model.fit(X_train_ohe, Y_train)\n",
    "\n",
    "ohe_prediction = model.predict(X_test_ohe)\n",
    "print(\"RMSLE (One hot encoder) :\", root_mean_squared_logarithmic_error(Y_test, ohe_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Pipeline\n",
    "\n",
    "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс — pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)).\n",
    "\n",
    "**7. Напишите пайплайн, объединяющий использованную нами базовую предобработку данных (BaseDataPreprocessor и OneHotPreprocessor), а также линейную регрессию с L2-регуляризацией, и сдайте его в Контест.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def make_ultimate_pipeline(continuous_columns, categorical_columns):\n",
    "    one_hot_preprocessor = OneHotPreprocessor(columns_to_encode=categorical_columns, continue_columns=continuous_columns)\n",
    "    \n",
    "    # Пайплайн с двумя препроцессорами и линейной регрессией\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor' BaseDataPreprocessor()),\n",
    "        ('preprocessorOneHot', one_hot_preprocessor), # Масштабирование данных числовых фичей включено\n",
    "        ('regressor', ExponentialLinearRegression())\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE (Pipeline): 0.16879940919250136\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_ultimate_pipeline(continuous_columns, categorical_columns)\n",
    "pipeline.fit(data_train, Y_train)\n",
    "y_pred = pipeline.predict(data_test)\n",
    "\n",
    "print(\"RMSLE (Pipeline):\", root_mean_squared_logarithmic_error(Y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
